\chapter{Introduction}
\label{sec:Introduction}

The rare $\Lb\to\Lz\mumu$ decay is a FCNC decay governed by the $\bquark \to \squark\mumu$ quark
level transition. In the SM this decay proceeds through electroweak penguin and \W box diagrams
(see Fig.~\ref{fig:penguins}). Since this process happens only through loop diagrams, it is highly sensitive
to new particles entering the loops. Moreover, as final state contains only a single long-lived hadron,
the hadronic physics is easier to handle than in fully hadronic decays.
%\begin{figure}[hbt]
%\centering
%\includegraphics[width=0.8\textwidth]{Lmumu/figs/penguins3.png}
%\caption{Loop Feynmann diagrams for the rare $b \rightarrow s $ decay.}
%\label{fig:penguins}
%\end{figure}

Interest in \Lb baryon decays arises from two important facts.
First of all, as \Lb has non-zero initial spin, there is a potential to learn information about the helicity structure
of the underlying Hamiltonian, which cannot be extracted from the meson decays~\cite{Hiller:2007ur,Mannel:1997xy}.
Second, as \Lb baryon is in first approximation
composed of heavy quark and di-quark formed of light quarks the hadronic physics significantly differs from that of the mesons.
This itself provides possibility to better understand and test the hadronic physics in the theory,
which could yield improved understanding and confidence also for mesons.

With respect of \Bz decays going though the same transitions, such as \BdToKstmm, \Lz can provide independent
confirmations of the results as it involves the same operators but different hadronic matrix elements.
Furthermore, \Lz decays weakly and therefore complementary constraints with respect to \Bz decays can be extracted.
Finally, the narrow width approximation, used in theoretical calculation is fully applicable in the \Lb case,
which has $\Gamma_{\Lb} \sim 2.5 \cdot 10^{-6}$ \ev. This is not assured using \BdToKstmm because
the contribution from $\decay{\Bz}{K\pi\mumu}$ is unconstrained.

Theoretical aspects of the $\Lb\to\Lz\mumu$ decays were considered by a number of authors both in the SM and in different new physics scenarios
\cite{Aslam:2008hp,Wang:2008sm,Huang:1998ek,Chen:2001ki,Chen:2001zc,Chen:2001sj,Zolfagharpour:2007eh,Mott:2011cx,Aliev:2010uy,Mohanta:2010eb,Sahoo:2011yb}.
All authors start from the same effective Hamiltonian already described in Sec.~\ref{sec:Effective_Hamiltonian}. However, form factors, describing hadronic physics, are not developed as well as in the meson case.
Since there are not as many experimental constraints and form factors are still not well understood this leads to a relatively
large spread in predicted branching fractions. An interesting quantity to study is the differential branching fraction as
function of \qsq. This still suffers from knowledge of form factors, but as different
approaches to form factors are applicable in different \qsq regions, this allows a more meaningful comparison to theory.

Experimentally, the decay $\Lb\to\Lz\mumu$ was observed for the first time in 2011 by the CDF collaboration
\cite{Aaltonen:2011qs}, with signal yield of $24\pm5$ signal events. Later this was updated using the full
CDF statistics~\cite{CDF:10894}. Their preliminary result on full statistics yields
$\mathcal{B}($\Lb\to\Lz\mumu$) =[1.95\pm0.34(\mathrm{stat})\pm0.61(\mathrm{syst})]\times 10^{-6}$. CDF observed the signal
only in the \qsq region above the square of the \psitwos mass.
Recently, the decay was observed also at LHCb~\cite{LHCb-PAPER-2013-025} with a yield of $78\pm12$ signal events
using 1 \invfb of integrated luminosity collected in 2011. The signal was again found only in the high \qsq region.
The LHCb result for the branching fraction relative to the $J/\psi\Lambda$ decay, used as normalisation channel, is 
%
\begin{equation*}
\mathcal{B}(\Lb\to\Lz\mumu)/\mathcal{B}(\Lb\to\jpsi\Lz)=[1.54\pm0.30(\mathrm{stat})\pm0.20(\mathrm{syst})\pm0.02(\mathrm{norm})]\times 10^{-3} 
\end{equation*}
and for absolute branching fraction
\begin{equation*}
\mathcal{B}(\Lb\to\Lz\mumu) =[0.96\pm0.16(\mathrm{stat})\pm0.13(\mathrm{syst})\pm0.21(\mathrm{norm})]\times 10^{-6}.
\end{equation*}

This parts of the thesis describes the measurement of the differential branching fraction
of the $\Lb\to\Lz\mumu$ normalised by $J/\psi\Lambda$ using 3 \invfb of $pp$ collisions collected in 2011 and 2012.
Furthermore an angular analysis of these decays is performed, measuring observables including
the forward-backward asymmetries in the leptonic and hadronic systems.

\section{Analysis strategy and \qsq regions}
\label{sec:Lb_q2choice}

A typical \qsq spectrum of $\bquark\to\squark\ell\ell$ decays was shown in Fig.~\ref{fig:q2spectrum}.
This is characterised by the presence of the narrow peaks of the \jpsi and \psitwos resonances.
For this analysis two regions are defined: the ``low \qsq" region, below the \jpsi resonance ($\qsq < 8$ \gevgevcccc),
where the signal is unobserved, and the ``high \qsq" region, above the \jpsi resonance ($\qsq > 11$ \gevgevcccc).
The decay \Lb\to\jpsi\Lz, where \jpsi decays into two muons, which had same final states as the signal,
is used as a normalisation channel and the branching fraction measurement is given in relative form
fo limit systematic uncertainties. In both cases the \Lz decay mode into a pion and a proton, $\Lz\to p\pi$,
is used to reconstruct the decays. The rare and normalisation channels are naturally distinguished
by the \qsq interval the fall into. The regions in which the rare channel is studied include:
\begin{itemize}
\item $0.1 < \qsq < 8$ \gevgevcccc, where the selection is optimised to observed the signal as explained in Sec.~\ref{sec:Lb_mva_opt}.
The upper bound of this interval was chosen to be sufficiently far from the \jpsi radiative tail at low masses, that
could contaminate the rare sample;
\item  $11 < \qsq < 12.5$ \gevgevcccc in between two charmonium resonances and \\$\qsq>15$ \gevgevcccc, above \psitwos.
In these two intervals the selection is optimised to maximise the yield which is particularly important
for a stable angular analysis.
\end{itemize}
The above ragions are then divided in smaller intervals, as much as the available statistics allows, which results
in bins $\sim 2$ \gevgevcccc wide. The binning used is the following 
\begin{equation}
[0.1, 2.0, 4.0, 6.0, 8.0], \jpsi, [11.0, 12.5], \psitwos, [15.0, 16.0, 18.0, 20.0].
\end{equation}

In addition the result is provided also in two integrated regions:
\begin{itemize}
\item 1.1-6.0 \gevgevcccc: this interval is theoretically clean since is far from the
photon pole, which dominated at low \qsq, washing out the sensitivity to NP contributions.
The lower bound of this interval it chosen excludes the possible contribution from
from the $\phi$ resonance, which appears at 1 \gevgevcccc. The upper bound of the interval
is chosen to totally exclude a small contribution from the \jpsi resonance that leaks
below 8 \gevgevcccc.
\item 15.0-20.0 \gevgevcccc: this interval is the one that contains most of the
statistics and it is used as a natural cross check that the analysis in smaller bins is stable.
\end{itemize}

\section{Candidate types}

This analysis deals with \Lz baryons, which have a lifetime of $(2.632 \pm 0.020 ) \times 10^{-10}$ s~\cite{PDG2014}.
These are considered long-lived particles in particle physics terms and can travel into the
detector for several meters generating well distinguished secondary vertices.
In LHCb \Lz baryons can be reconstructed from tracks with out without hits in the VELO and
therefore with define two candidates types as follows:

\begin{itemize}
\item {\bf Long candidates}: built from tracks which have hits in the VELO, ``long tracks".
These candidats, also denoted as ``LL", are characterised by a better momentum resolution
thanks to the longer leverage arm available to long tracks.
\item {\bf Downstream candidates}: built from tracks without hits in the VELO, ``downstream tracks", also denoted as ``DD".
\end{itemize}

Figure~\ref{fig:track_types} shows a depiction of the two types of candidates used in the analysis
together with the other possible types in LHCb which are not used in this analysis.
As the long and downstream candidate categories are characterised by different resolution and different
kinematic properties the analysis is performed separately on the two and the results are then combined.

\begin{figure}[hbt]
\centering
\includegraphics[width=0.8\textwidth,trim=0cm 0cm 0cm 5mm,]{Lmumu/figs/track_types.png}
\caption{Representation of the two \Lz candidate types built from ``long" and ``downstream" tracks.}
\label{fig:track_types}
\end{figure}
 
\section{Simulation}
\label{sec:Lb_simulation}

Samples of simulated events are needed in order to train the multivariate classifier
(see Sec.~\ref{sec:Lb_mva}), calculate the selection efficiency and study possible background.
In particular for this analysis one sample of $\sim 2$ millions \Lb\to\jpsi\Lz and 
$\sim 5$ millions $\Lb\to\Lz\mumu$ simulated events are used.
Samples of simulated $\Bz\ra\jpsi\KS$, $\Bz\ra\KS\mumu$ and $B^{+} \ra\mumu K^{*+}$
events are also used to study backgrounds from these decays. The events are generated using
Pythia8, hadronic particle are decayed using EvtGen and Geant4 is used to simulate
the interaction of final state particles with the detector. Simulated events are then
reconstructed using the same reconstruction version used for real data. The L0 hadware
trigger is emulated in the simulation while for the software stage, Hlt1 and Hlt2
(see Sec.~\ref{sec:det_trigger}) the same code can be used as done for real data.
Events are are simulated using both 2011 and 2012 conditions in the same amount in which data is available.
It is important that the simulation gives an accurate description of the data especially
for quantitative estimations, as the extraction of efficiencies. While the simulation
gives a generally good description of data some discrepancies remain. The next sections
describe corrections applied to the simulation in order to have a better description of data.
In App.~\ref{app:MC_data_comp} data distributions are compared with simulated ones.

\subsection{Decay Model}
\label{decaymodel}

As little is known about \Lb decays structure, the simulation software generates events
according to phase space decay. To include a reasonably realistic \qsq dependence,
the simulation is weighted using decays amplitudes based on the predictions in Ref.~\cite{Gutsche:2013pp}.
Equations in this paper are for case of unpolarised production and we extend those to include polarisation.
Details of this are in Appendix~\ref{ap:LbLmumuAngular}. The value of the \Lb production polarisation 
used in the calculations is of $P_b = 0.06$ as measured by LHCb~\cite{Aaij:2013oxa}. 
%In the weight calculation we always use generator level
%momenta to obtain \qsq and corresponding angles.
Fig.~\ref{fig:wilson_q2} shows the phase space \qsq distribution and the one obtained re-weighting the events.
This can be qualitatively compared to the \qsq spectrum of a generic $\bquark\to\squark\ell\ell$ decay
reported in Fig.~\ref{fig:q2spectrum}
%
\begin{figure}
\centering
\includegraphics[width=0.48\textwidth]{Lmumu/figs/Q2_beforemodel.pdf}
\includegraphics[width=0.48\textwidth]{Lmumu/figs/Q2_aftermodel.pdf}
\caption{The \qsq spectrum of $\Lb\to\Lz\mumu$ simulates events according to the
phase space of the decay (left) and reweighted using the decay amplitudes (right).}
\label{fig:decaymodeleffonq2}
\end{figure}
%
For the normalisation mode, the decay model used is described in Appendix~\ref{ap:LbJpsiLAngular},
with amplitude magnitudes and production polarisation taken from the measurement in
Ref.~\cite{Aaij:2013oxa}. Phases are not yet measured and are all set to zero.

\subsection{Kinematic re-weighting}
\label{sec:kinWeight}

Small data-simulation differences are found in the kinematic properties of the mother particle, \Lb,
which then affect also the final state particles. The Monte Carlo is re-weighted by 
comparing the two-dimensional momentum and transverse momentum of \Lb and \Lz between
real and simulated \Lb\to\jpsi\Lz which passed pre-selection.
To work with a data sample as clean as possible, a narrow interval around \jpsi and \Lb peaks is selected.
Then the \Lb invariant mass is to extract the amount of background under the peak.
The background fraction with respect to the signal, $f_b$, is then used to statistically
subtract the background from the kinematical distributions as described by the following equation
%
\begin{equation}
S(p,\pt) = T(p,\pt) - f_b\cdot B(p,\pt),
\end{equation}
\noindent
where $S(p,\pt)$ is the distribution of pure signal events which we want to obtain, $T(p,\pt)$ is the total
distribution of signal plus background, namely the distribution of all events in the signal interval
($5605 < m(p\pi\mumu) < 5635 \mevcc$) and $B(p,\pt)$ is the pure background
distribution obtained using events from the upper sideband ($m(p\pi\mumu) > 5800 \mevcc$).

After obtaining the signal ditributions from data this is compared with $\Lb\to\Lz\mumu$ simulated events
and a weight, $w(p_{\Lb},\pt_{\Lb})$ is defined by taking the ratio of the two dimensional distributions.
The result is shown in Fig.~\ref{fig:kinWeight}. In appendix \ref{app:MC_data_comp} are shown distributions
of sideband subtracted data in the signal and sideband regions and weighted and unweighted Monte Carlo events.
In these plots the \Lb distributions match by construction but the re-weighting improves also the agreement 
between the transverse momentum distributions of all final particles. Small differences remain due to
the finite binning used for the weights calculation. Quality variables, such as the $\chi^2$ of tracks
and vertices, show little dependence on the kinematics and are relatively unaffected by the weighting procedure.

\begin{figure}
\centering
\includegraphics[width=0.9\textwidth]{Lmumu/figs/ratio_Lb_p_pt.pdf}
 \caption{Weights used for the kinematical reweighting as a function of the momentum and transverse momentum of \Lb. }
\label{fig:kinWeight}
\end{figure}

\subsection{Event type}

The fraction of \Lz reconstructed from long tracks and downstream tracks does not fully agree between data and simulation.
For \Lb\to\jpsi\Lz decays which passed the full selection, $\sim 70\%$ of candidates are reconstructed from downstream tracks.
On the contrary, in the simulation of the same decay, $\sim 75\%$ of candidates are reconstructed from downstream tracks.
The fraction of downstream and long tracks also varies as a function of \qsq and he biggest differences are found at low \qsq.
In order to deal with this difference all efficiencies separately for downstream and long events and the analysis is done 
separately for the two categories, joining results at the end. It is therefore not required to correct the simulation
to reproduce the correct fraction of events in each category.

